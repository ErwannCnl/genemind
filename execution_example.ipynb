{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f860d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9d6d903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"genes\": [\n",
      "    \"TP53\",\n",
      "    \"AKT3\",\n",
      "    \"EGFR\",\n",
      "    \"ATRX\",\n",
      "    \"PDX1\"\n",
      "  ],\n",
      "  \"organism\": \"Homo sapiens\",\n",
      "  \"field_of_study\": \"cancer genomics\",\n",
      "  \"organ\": \"brain\",\n",
      "  \"analysis_type\": \"mutation enrichment analysis\",\n",
      "  \"GSEA\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Initialise LLM (Gemini 2.5)\n",
    "llm = init_chat_model(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    model_provider=\"google_genai\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# Canonical user input\n",
    "paragraph = (\n",
    "    \"I identified these five genes to be significantly more mutated than expected by chance in my cohort of human brain cancer patients: TP53, AKT3, EGFR, ATRX and PDX1. Do a GSEA\"\n",
    ")\n",
    "\n",
    "# Define Pydantic class for input genes and context\n",
    "class StudyExtraction(BaseModel):\n",
    "    genes: List[str] = Field(\n",
    "        description=\"List of gene symbols mentioned in the text, normalized to official HGNC/NCBI-style symbols if possible.\"\n",
    "    )\n",
    "    organism: Optional[str] = Field(\n",
    "        description=\"Scientific name (binomial) of the organism (e.g., 'Homo sapiens', 'Mus musculus').\"\n",
    "    )\n",
    "    field_of_study: Optional[str] = Field(\n",
    "        description=\"High-level biomedical domain, e.g., 'oncology', 'cancer genomics', 'neuroscience', 'immunology', 'microbiology'.\"\n",
    "    )\n",
    "    organ: Optional[str] = Field(\n",
    "        description=\"Primary organ or tissue referenced (e.g., 'brain', 'liver', 'blood').\"\n",
    "    )\n",
    "    analysis_type: Optional[str] = Field(\n",
    "        description=\"Concise description of the analysis performed, e.g., 'differential expression', 'mutation enrichment', 'GWAS', 'copy-number analysis', 'metagenomic profiling'.\"\n",
    "    )\n",
    "    GSEA: bool = Field(default=False, \n",
    "                       description=\"Whether the user mentions that a GSEA is needed on the gene set. If no mention, keep it False.\")\n",
    "\n",
    "#alternative implementation to parse as pydantic more robustly\n",
    "parser = PydanticOutputParser(pydantic_object=StudyExtraction)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract per schema:\\n{format_instructions}\"),\n",
    "    (\"human\", \"{paragraph}\"),\n",
    "]).partial(format_instructions=format_instructions)\n",
    "parsing_llm = prompt | llm | parser\n",
    "\n",
    "# pass raw user input \"paragraph\"\n",
    "parsed_input = parsing_llm.invoke({\"paragraph\": paragraph})\n",
    "#convert to JSON string\n",
    "json_output = parsed_input.model_dump_json(indent=2)\n",
    "print(json_output)\n",
    "\n",
    "#next step - inject the json to the LLM to determine attributes to fetch from BioMart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e73c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.querries_script import group_by_gene_dynamic, fill_with_ncbi, call_querry_biomart\n",
    "import pandas as pd    \n",
    "\n",
    "attributes = pd.read_csv(\"data/attributes.csv\")[\"name\"].to_list()\n",
    "\n",
    "output = call_querry_biomart(attributes=attributes[:15],\n",
    "                            filters={\"external_gene_name\": parsed_input.genes})\n",
    "\n",
    "output = group_by_gene_dynamic(output)\n",
    "\n",
    "output = fill_with_ncbi(output)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1f5fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from gseapy import enrichr\n",
    "\n",
    "def enrichr_query(gene_list: list):\n",
    "    \"\"\"Run enrichment analysis on a list of genes.\n",
    "\n",
    "    This tool allows to run enrichment analysis on a list of genes using the `gseapy` library.\n",
    "    Using this tool, a model can get information about the biological processes enriched in a set of genes.\n",
    "\n",
    "    Args:\n",
    "        gene_list: list of genes to run enrichment analysis on\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the enrichment results\n",
    "    \"\"\"\n",
    "    # Run enrichment\n",
    "    enr = enrichr(\n",
    "        gene_list=gene_list,\n",
    "        gene_sets='GO_Biological_Process_2021',\n",
    "        organism='Human',\n",
    "        outdir=None,  # no files will be written\n",
    "        cutoff=0.05\n",
    "    )\n",
    "\n",
    "    # Save results as DataFrame\n",
    "    df_results = enr.results\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a76ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if parsed_input.GSEA: \n",
    "    tool_results = enrichr_query(parsed_input.genes)\n",
    "\n",
    "        # Optionally, format or reduce the output for readability (e.g., top rows)\n",
    "    if not tool_results.empty:\n",
    "        # Filter rows where Adjusted P-value < 0.05\n",
    "        filtered_df = tool_results[tool_results[\"Adjusted P-value\"] < 0.05]\n",
    "\n",
    "        # Drop the 'Gene_set' column\n",
    "        filtered_df = filtered_df.drop(columns=[\"Gene_set\",\"Old P-value\",\"Old Adjusted P-value\"])\n",
    "        gsea_string = \"the results of gene set enrichment are:\\n \"+ filtered_df.head(20).to_string(index = False)\n",
    "        # Show the top rows\n",
    "        # print(gsea_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "text = str(output)\n",
    "\n",
    "task ='''\n",
    "<task>\n",
    "You are a helpful and biological expert specializing in integrating and interpreting gene-related data from the given information report, combined with the knowledge you have obtained during your training.\n",
    "When given a report on a set of genes, summarize the key insights for each gene. The final and most important job is to concisely contextualise the user's findings with biological or biomedical background knowledge and find commonalities between the genes given. Stay to-the-point and scientifically accurate. Tailor the response to the context given by the client.\n",
    "Think hard!\n",
    "</task>\n",
    "'''\n",
    "\n",
    "user_prompt = \"I want to know more about these genes {input_g}. They were obtained after {analyses} in {organism}. All information I know about these genes is the following: {text} \\n Do you find any commonalities or interesting findings about these genes? I'm mainly interested in {context}\"\n",
    "if parsed_input.GSEA:\n",
    "    user_prompt += gsea_string\n",
    "    \n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", task),\n",
    "    (\"user\", user_prompt)\n",
    "])\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"text\": text, \"input_g\": parsed_input.genes, \"context\": parsed_input.field_of_study, \"analyses\": parsed_input.analysis_type, \"organism\": parsed_input.organism})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-summerschool-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
